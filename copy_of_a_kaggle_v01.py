# -*- coding: utf-8 -*-
"""Copy of A-KAggle_v01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OJMVl57t6SfbEx1236_qzZNYhahOCHE2
"""

from google.colab import drive
drive.mount('/gdrive')

cd /gdrive/My\ Drive/notebooks/Arghavan

import numpy as np
from scipy.io import loadmat
# mat1 = loadmat('../../kaggle/brain/train/data/train_subject01.mat')
# mat2 = loadmat('../../kaggle/brain/train/data/train_subject01.mat')

X = []
y = []


for i in range(1,17):
    try:
        dd = loadmat('../../kaggle/brain/train/data/train_subject'+str(i).zfill(2)+'.mat')
        X.append(dd['X'])
        y.append(dd['y'])
    except:
        print(i)
X = np.concatenate(X,axis=0)
y = np.concatenate(y,axis=0)

print(X.shape,y.shape)

ls ../../kaggle/brain/test/data/*

# x_test = []
# y_test = []

# for i in range(17,24):
# #     try:
#         dd = loadmat('../../kaggle/brain/test/data/test_subject'+str(i)+'.mat')
#         x_test.append(dd['X'])
#         y_test.append(dd['y'])
# #     except:
# #         print(i)
# # x_test = np.concatenate(x_test,axis=0)
# # y_test = np.concatenate(y_test,axis=0)



print()

print(mat.keys())

x = mat['X']
y = mat['y']

x.shape

y.shape

from keras.utils import to_categorical

# X = x+0
inds = np.arange(X.shape[0])
np.random.shuffle(inds)
n_train = 6500
X_train = X[inds[:n_train]]
y_train = y[inds[:n_train]]
X_test = X[inds[n_train:]]
y_test = y[inds[n_train:]]


xmax = X_train.max()
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= xmax
X_test /= xmax
del X


n_train, img_rows, img_cols = X_train.shape
X_train = X_train.reshape(n_train, img_rows, img_cols, 1)
n_test, img_rows, img_cols = X_test.shape
X_test = X_test.reshape(n_test, img_rows, img_cols, 1)
input_shape = (img_rows, img_cols, 1)

# def indices_to_one_hot(data, nb_classes):
#     """Convert an iterable of indices to one-hot encoded labels."""
#     targets = np.array(data).reshape(-1)
#     return np.eye(nb_classes)[targets]

# y_train = indices_to_one_hot(y_train, 24)
# y_test = indices_to_one_hot(y_test, 24)
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

print('x_train shape:', X_train.shape)
print(X_train.shape[0], 'train samples')
print(X_test.shape[0], 'test samples')
print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)



from __future__ import print_function
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K

num_classes = 2

model = Sequential()
model.add(Conv2D(8, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape,
                 padding='same'))

model.add(Conv2D(4, (41, 41), activation='relu',padding='same'))
model.add(Conv2D(4, (21, 21), activation='relu',padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(4, (11,11), activation='relu',padding='same'))
# model.add(Conv2D(16, (9, 9), activation='relu',padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(16, (5, 5), activation='relu',padding='same'))
# model.add(Conv2D(16, (9, 9), activation='relu',padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, (3, 3), activation='relu',padding='same'))
# model.add(Conv2D(16, (9, 9), activation='relu',padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))
# model.add(Conv2D(16, (9, 9), activation='relu',padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(16, (3, 3), activation='relu',padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
# model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])
model.summary()

batch_size = 500
epochs = 10
model.fit(X_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(X_test, y_test))
score = model.evaluate(X_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])



from __future__ import print_function
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv1D, MaxPooling1D
from keras import backend as K

num_classes = 2

model = Sequential()
model.add(Conv1D(4, kernel_size=41,
                 activation='relu',
                 input_shape=(114750, 1), 
                 padding='same'))

model.add(Conv1D(4, 41, activation='relu',padding='same'))
model.add(Conv1D(4, 41, activation='relu',padding='same'))
model.add(MaxPooling1D(pool_size=5))
model.add(Conv1D(4, 11, activation='relu',padding='same'))
model.add(MaxPooling1D(pool_size=5))

model.add(Conv1D(16, 5, activation='relu',padding='same'))
model.add(MaxPooling1D(pool_size=5))

model.add(Conv1D(16, 3, activation='relu',padding='same'))
model.add(MaxPooling1D(pool_size=5))

# model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
# model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])
model.summary()

batch_size = 100
epochs = 10
model.fit(X_train.reshape(500,-1,1), y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(X_test.reshape(94,-1,1), y_test))
score = model.evaluate(X_test.reshape(94,-1,1), y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])



#RandomForest

X = []
y = []


for i in range(1,17):
    try:
        dd = loadmat('../../kaggle/brain/train/data/train_subject'+str(i).zfill(2)+'.mat')
        X.append(dd['X'])
        y.append(dd['y'])
    except:
        print(i)
X = np.concatenate(X,axis=0)
y = np.concatenate(y,axis=0)



X = X.reshape(8828,-1)[:,:6500]

inds = np.arange(X.shape[0])

from keras.utils import to_categorical

# X = x+0
inds = np.arange(X.shape[0])
np.random.shuffle(inds)
n_train = 6500
X_train = X[inds[:n_train]]
y_train = y[inds[:n_train]]
X_test = X[inds[n_train:]]
y_test = y[inds[n_train:]]
print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)

X_train.shape

from sklearn.ensemble import RandomForestClassifier as RFC

rfc = RFC()

rfc.fit(X_train,y_train)

rfc.score(X_test,y_test)